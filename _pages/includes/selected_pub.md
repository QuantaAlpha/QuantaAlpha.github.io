
# üìù Publications and Preprints

My full paper list can be seen at [Google Scholar](https://scholar.google.com/citations?user=Dx3z0m8AAAAJ) and [Full List of Publications and Preprints](/publications/).

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/adv_fed.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<u>Y. Li</u>, Y. Gao, and H. Wang, ‚Äú**Understanding adversarial transferability in federated learning**,‚Äù arXiv preprint arXiv:2310.00616, 2023.

[Preprint (TMLR submission)](https://arxiv.org/pdf/2310.00616.pdf)

[Paper](https://arxiv.org/pdf/2310.00616.pdf) | [Arxiv](https://arxiv.org/abs/2310.00616) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:bUvOv5WBHlEJ:scholar.google.com/&output=citation&scisdr=ClG4v9jUEM_EiSJym20:AFWwaeYAAAAAZYh0g20XIWMI9_xhIT4KUHPbkTw&scisig=AFWwaeYAAAAAZYh0g5JAuxYpOKwznqR7dQhV9Jk&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/llm_dg.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<u>Li Y</u>, Ren S, Deng W, et al. Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapolation. arXiv preprint arXiv:2403.05523.

[Preprint (ECCV2024 submission)](https://arxiv.org/abs/2403.05523)

[Paper](https://arxiv.org/abs/2403.05523) | [Arxiv](https://arxiv.org/abs/2403.05523) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:wKCaJBEOyo8J:scholar.google.com/&output=citation&scisdr=ClH8_vnCEPaKl1OB9jk:AFWwaeYAAAAAZfyH7jjPvumQwmf91jrpK0FG8E4&scisig=AFWwaeYAAAAAZfyH7n3Bye0BdVGuGtpQRhh3k50&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/robust_dd.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

E. Xue, <u>Y. Li</u>, H. Liu, Y. Shen, and H. Wang, ‚ÄúTowards adversarially robust dataset distillation by curvature regularization,‚Äù arXiv preprint arXiv: 2403.10045, 2024.

[Preprint (ECCV2024 submission)](https://arxiv.org/pdf/2403.10045.pdf)

[Paper](https://arxiv.org/pdf/2403.10045.pdf) | [Arxiv](https://arxiv.org/pdf/2403.10045.pdf) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:bPocUDsrFBYJ:scholar.google.com/&output=citation&scisdr=ClH8_vnCEPaKl1OOp6c:AFWwaeYAAAAAZfyIv6bfgAZRYuQoYuf6J4UdvEI&scisig=AFWwaeYAAAAAZfyIv4MexAhI6cBf6ePw39RaI3c&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/dd_ot.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

H. Liu, <u>L. Li</u>, T. Xing, V. Dalal, J. He, and H. Wang, ‚ÄúDataset distillation via the wasserstein metric,‚Äù arXiv preprint arXiv: 2311.18531, 2023.

[Preprint (ECCV2024 submission)](https://arxiv.org/pdf/2311.18531.pdf)

[Paper](https://arxiv.org/pdf/2311.18531.pdf) | [Arxiv](https://arxiv.org/pdf/2311.18531.pdf) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:EPtoQ3d3T4QJ:scholar.google.com/&output=citation&scisdr=ClH8_vnCEPaKl1OPgIQ:AFWwaeYAAAAAZfyJmIXdUfYrDCKAKD1lcUHIQys&scisig=AFWwaeYAAAAAZfyJmGThJz36iBIxuNEi8oNvbiA&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/diverse_cotraining.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<u>Y. Li</u>, X. Wang, L. Yang, L. Feng, W. Zhang, and Y. Gao, ‚Äú**Diverse co-training makes strong semi-supervised segmentor**,‚Äù in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 16055‚Äì16067, 2023.

[ICCV 2023](https://iccv2023.thecvf.com/)

[Paper](https://arxiv.org/pdf/2308.09281.pdf) | [Code](https://github.com/williamium3000/diverse-cotraining) | [Arxiv](https://arxiv.org/abs/2308.09281) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:dV2NZtJDfXoJ:scholar.google.com/&output=citation&scisdr=ClG4v9jUEM_EiSJ1viA:AFWwaeYAAAAAZYhzpiAXLJBN6QpiXFLUzuQvYyU&scisig=AFWwaeYAAAAAZYhzpjSprsR_quud7OifXFkyNrM&scisf=4&ct=citation&cd=-1&hl=zh-CN&scfhb=1)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/multi_metrics.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

S. Huang, <u>Y. Li</u>, C. Chen, L. Shi, and Y. Gao, ‚Äú**Multi-metrics adaptively identifies backdoors in federated learning**,‚Äù in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 4652‚Äì4662, October 2023.

[ICCV 2023](https://iccv2023.thecvf.com/)

[Paper](https://arxiv.org/pdf/2308.09281.pdf) | [Code](https://github.com/siquanhuang/Multi-metrics) | [Arxiv](https://arxiv.org/abs/2308.09281) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:NlVpANU8-jUJ:scholar.google.com/&output=citation&scisdr=ClG4v9jUEM_EiSJyAhE:AFWwaeYAAAAAZYh0GhE1qC-xfJX3O-kr5JRGvvA&scisig=AFWwaeYAAAAAZYh0GiOlBbhVJVwY2KHahyaogHI&scisf=4&ct=citation&cd=-1&hl=zh-CN&scfhb=1)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/consistent_teacher.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

X. Wang, X. Yang, S. Zhang, Y. <u>Y. Li</u>. Feng, S. Fang, C. Lyu, K. Chen, and W. Zhang, ‚Äú**Consistent-teacher: Towards reducing inconsis- tent pseudo-targets in semi-supervised object detection**,‚Äù in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3240‚Äì3249, 2023.

[CVPR 2023](https://cvpr2023.thecvf.com/) (<span style="color:red">Highlight Top 2.5%</span>)

[Project Page](https://adamdad.github.io/consistentteacher/) | [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Consistent-Teacher_Towards_Reducing_Inconsistent_Pseudo-Targets_in_Semi-Supervised_Object_Detection_CVPR_2023_paper.pdf) | [Code](https://github.com/Adamdad/ConsistentTeacher) | [Arxiv](https://arxiv.org/abs/2209.01589) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:DjViT-DgiC8J:scholar.google.com/&output=citation&scisdr=ClG4v9jUEM_EiSJzjvk:AFWwaeYAAAAAZYh1lvlHNBp3jgCyyzACdSjfF4M&scisig=AFWwaeYAAAAAZYh1lku3TLx9TO8bRyWYkIsAs7k&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">BIBM 2022</div><img src='images/more_than_decoder.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


<u>Y. Li</u>, W. Cai, Y. Gao, C. Li, and X. Hu, ‚Äú**More than encoder: Introducing transformer decoder to upsample**,‚Äù in 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 1597‚Äì1602, IEEE, 2022.

[BIBM 2022](https://ieeebibm.org/BIBM2022/)

[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9995378) | [Arxiv](https://arxiv.org/abs/2106.10637) | [BibTex](https://scholar.googleusercontent.com/scholar.bib?q=info:5F3wAfOjTgcJ:scholar.google.com/&output=citation&scisdr=ClG4v9jUEM_EiSJ-_SI:AFWwaeYAAAAAZYh45SL5W6FbsuSSDa4mFD8908I&scisig=AFWwaeYAAAAAZYh45SoysyweRLmhvPTzlIbSBWs&scisf=4&ct=citation&cd=-1&hl=zh-CN)
</div>
</div>
